{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# 用tensorflow 导入数据\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置GPU按需增长\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-14e1bed2fe91>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../data/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../data/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../data/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../data/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(10000, 10)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../data/MNIST_data', one_hot=True) \n",
    "# 看看咱们样本的数量\n",
    "print(mnist.test.labels.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "input_size = 28      # 每个时刻的输入特征是28维的，就是每个时刻输入一行，一行有 28 个像素\n",
    "timestep_size = 28   # 时序持续长度为28，即每做一次预测，需要先输入28行\n",
    "hidden_size = 256    # 隐含层的数量\n",
    "layer_num = 2        # LSTM layer 的层数\n",
    "class_num = 10       # 最后输出分类类别数量，如果是回归预测的话应该是 1\n",
    "cell_type = \"lstm\"   # lstm 或者 block_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.float32, [None, class_num])\n",
    "batch_size = tf.placeholder(tf.int32, [])\n",
    "keep_prob = tf.placeholder(tf.float32, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# RNN 的输入shape = (batch_size, timestep_size, input_size) \n",
    "X = tf.reshape(X_input, [-1,28,28])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(cell_type, num_nodes, keep_prob):\n",
    "    assert (cell_type in ['lstm', 'block_lstm'], 'wrong type')\n",
    "    if cell_type == 'lstm':\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(num_nodes)\n",
    "    else:\n",
    "        cell = tf.contrib.rnn.LSTMBlockCell(num_units=num_nodes)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlstm_cell = tf.contrib.rnn.MultiRNNCell(\n",
    "    [lstm_cell(cell_type, hidden_size, keep_prob) for _ in range(layer_num)], \n",
    "    state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = mlstm_cell.zero_state(batch_size=batch_size, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, state = tf.nn.dynamic_rnn(mlstm_cell, inputs=X, initial_state=init_state, time_major=False)\n",
    "# print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_state = state[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([hidden_size, class_num]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[class_num], dtype=tf.float32))\n",
    "y_pre = tf.nn.softmax(tf.matmul(h_state, W) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_mean(y_input*tf.log(y_pre))\n",
    "tf.summary.scalar('cross_entropy',cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred = tf.equal(tf.argmax(y_pre,1), tf.argmax(y_input,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, 'float'))\n",
    "tf.summary.scalar('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_writer = tf.summary.FileWriter('./log', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, train cost=0.234208, acc=0.156250; test cost=0.243825, acc=0.184375; pass 8.099560022354126s\n",
      "step 51, train cost=0.092172, acc=0.750000; test cost=0.085505, acc=0.726719; pass 17.221086025238037s\n",
      "step 101, train cost=0.068696, acc=0.781250; test cost=0.048413, acc=0.844531; pass 17.318379163742065s\n",
      "step 151, train cost=0.043525, acc=0.890625; test cost=0.045675, acc=0.858750; pass 18.619638442993164s\n",
      "step 201, train cost=0.034354, acc=0.906250; test cost=0.028370, acc=0.915000; pass 17.23573398590088s\n",
      "step 251, train cost=0.029636, acc=0.890625; test cost=0.025004, acc=0.921250; pass 16.360023498535156s\n",
      "train finished\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):#1000\n",
    "    _batch_size = 64\n",
    "    X_batch, y_batch = mnist.train.next_batch(batch_size=_batch_size)\n",
    "    if i%50 == 0:\n",
    "        # 配置运行时需要记录的信息\n",
    "        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "        # 运行时记录运行信息的proto\n",
    "        run_metadata = tf.RunMetadata()\n",
    "        summary, cost, acc, _ = sess.run([merged, cross_entropy, accuracy, train_op], \n",
    "                                feed_dict={X_input:X_batch, y_input:y_batch,keep_prob:0.5,\n",
    "                                          batch_size:_batch_size},\n",
    "                                         options=run_options,\n",
    "                                         run_metadata=run_metadata)\n",
    "        # 将节点在运行时的信息写入日志文件\n",
    "        train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "    else:\n",
    "        summary, cost, acc, _ = sess.run([merged, cross_entropy, accuracy, train_op],\n",
    "                                feed_dict={X_input:X_batch, y_input:y_batch,keep_prob:0.5,\n",
    "                                        batch_size:_batch_size})\n",
    "    train_writer.add_summary(summary,i)\n",
    "    if i%50 == 0:\n",
    "        test_acc = 0.0\n",
    "        test_cost = 0.0\n",
    "        N = 100\n",
    "        for j in range(N):\n",
    "            X_batch, y_batch = mnist.test.next_batch(batch_size=_batch_size)\n",
    "            _cost, _acc = sess.run([cross_entropy, accuracy], \n",
    "                                   feed_dict={X_input:X_batch, y_input:y_batch, keep_prob:1.0, \n",
    "                                              batch_size:_batch_size})\n",
    "            test_acc += _acc\n",
    "            test_cost += _cost\n",
    "        print(\"step {}, train cost={:.6f}, acc={:.6f}; test cost={:.6f}, acc={:.6f}; pass {}s\".format(i+1, cost, acc, test_cost/N, test_acc/N, time.time() - time0))\n",
    "        time0 = time.time()\n",
    "print('train finished')\n",
    "train_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
