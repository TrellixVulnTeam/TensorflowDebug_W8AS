{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch 3.402614\n",
      "data_batch 3.092415\n",
      "data_batch -14.533257\n",
      "data_batch -9.013782\n",
      "data_batch 0.79917705\n",
      "data_batch 8.665041\n",
      "data_batch -1.1298261\n",
      "data_batch 3.6476848\n",
      "data_batch -4.1608233\n",
      "data_batch -3.9811556\n",
      "data_batch 2.8589833\n",
      "data_batch -10.593802\n",
      "data_batch -5.9337873\n",
      "data_batch 0.07398047\n",
      "data_batch -7.1772127\n",
      "data_batch 16.142195\n",
      "data_batch -1.8101554\n",
      "data_batch -11.166079\n",
      "data_batch 23.083813\n",
      "data_batch 17.002821\n",
      "data_batch 16.993977\n",
      "data_batch -7.34352\n",
      "data_batch 2.55986\n",
      "data_batch -13.509349\n",
      "data_batch 15.216166\n",
      "data_batch -3.2459476\n",
      "data_batch -0.1536495\n",
      "data_batch -3.8304949\n",
      "data_batch 10.185761\n",
      "data_batch 21.78749\n",
      "data_batch -16.165062\n",
      "data_batch -8.590998\n",
      "data_batch 14.716329\n",
      "data_batch -2.443162\n",
      "data_batch 9.720571\n",
      "data_batch 8.636861\n",
      "data_batch -8.118723\n",
      "data_batch -14.666856\n",
      "data_batch -4.596852\n",
      "data_batch -8.836729\n",
      "data_batch -10.357825\n",
      "data_batch 17.011059\n",
      "data_batch 4.169561\n",
      "data_batch -3.886105\n",
      "data_batch 11.2561455\n",
      "data_batch 8.900279\n",
      "data_batch -15.850155\n",
      "data_batch 2.8158908\n",
      "data_batch 10.9345875\n",
      "data_batch 14.313151\n",
      "data_batch 11.503088\n",
      "data_batch -0.4228325\n",
      "data_batch 2.2048497\n",
      "data_batch -3.497689\n",
      "data_batch 11.509642\n",
      "data_batch -8.3856735\n",
      "data_batch 1.6798702\n",
      "data_batch -9.421326\n",
      "data_batch 14.057255\n",
      "data_batch 7.527913\n",
      "data_batch -1.7283654\n",
      "data_batch 0.030861778\n",
      "data_batch -1.9381615\n",
      "data_batch 10.665673\n",
      "data_batch -1.9704922\n",
      "data_batch 15.506689\n",
      "data_batch 0.6723647\n",
      "data_batch -26.051983\n",
      "data_batch 8.245832\n",
      "data_batch 21.452898\n",
      "data_batch 3.7818053\n",
      "data_batch -2.5113492\n",
      "data_batch 22.48693\n",
      "data_batch -22.663616\n",
      "data_batch -8.879649\n",
      "data_batch -15.554366\n",
      "data_batch -2.183303\n",
      "data_batch 0.42017624\n",
      "data_batch 1.8544347\n",
      "data_batch 17.224426\n",
      "data_batch -25.17317\n",
      "data_batch -4.500091\n",
      "data_batch 7.281669\n",
      "data_batch -16.174623\n",
      "data_batch -4.258538\n",
      "data_batch 4.2185335\n",
      "data_batch 14.177641\n",
      "data_batch 8.147993\n",
      "data_batch -4.801646\n",
      "data_batch -10.39539\n",
      "data_batch -9.729188\n",
      "data_batch -5.468042\n",
      "data_batch 4.2199225\n",
      "data_batch -3.0602117\n",
      "data_batch 5.927545\n",
      "data_batch -16.310865\n",
      "data_batch -0.30465928\n",
      "data_batch -7.2996364\n",
      "data_batch -7.177456\n",
      "data_batch -2.394704\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "NUM_THREADS = 4\n",
    "# Generating some simple data\n",
    "# todo create 1000 random samples, each is a 1D array from the normal distribution (10, 1)\n",
    "train = 10 * np.random.randn(N_SAMPLES, 4) + 1\n",
    "# todo create 1000 random labels of 0 and 1\n",
    "labels = np.random.randint(1, 2, size=N_SAMPLES)\n",
    "# todo create FIFOQueue\n",
    "queue = tf.FIFOQueue(capacity=50, dtypes=[tf.float32, tf.int32], shapes=[[4], []])\n",
    "\n",
    "enqueue_op = queue.enqueue_many([train, labels])\n",
    "data_sample, label_sample = queue.dequeue()\n",
    "\n",
    "# create ops that do something with data_sample and label_sample\n",
    "\n",
    "# todo create NUM_THREADS to do enqueue\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * NUM_THREADS)\n",
    "with tf.Session() as sess:\n",
    "    # create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    for step in range(100):  # do to 100 iterations\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        data_batch, label_batch = sess.run([data_sample, label_sample])\n",
    "        print('data_batch', len(data_batch))\n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch -9.059171\n",
      "data_batch -6.079373\n",
      "data_batch 15.686863\n",
      "data_batch -7.0608544\n",
      "data_batch 13.298322\n",
      "data_batch 4.4754224\n",
      "data_batch -5.008146\n",
      "data_batch 4.3234425\n",
      "data_batch -7.228746\n",
      "data_batch 0.26499113\n",
      "data_batch -11.023543\n",
      "data_batch 11.453965\n",
      "data_batch 4.5807843\n",
      "data_batch -4.885458\n",
      "data_batch -7.0527334\n",
      "data_batch -4.466882\n",
      "data_batch -12.80364\n",
      "data_batch 10.463865\n",
      "data_batch 15.296938\n",
      "data_batch -15.415705\n",
      "data_batch 7.3205214\n",
      "data_batch -14.178363\n",
      "data_batch 7.0143123\n",
      "data_batch 19.315502\n",
      "data_batch 23.651167\n",
      "data_batch 29.578661\n",
      "data_batch -21.346228\n",
      "data_batch -7.545639\n",
      "data_batch -2.0845282\n",
      "data_batch 18.037764\n",
      "data_batch -16.84984\n",
      "data_batch 12.129198\n",
      "data_batch -8.30615\n",
      "data_batch -1.7670126\n",
      "data_batch 2.778209\n",
      "data_batch -16.912756\n",
      "data_batch 4.335661\n",
      "data_batch -4.192329\n",
      "data_batch -1.4783252\n",
      "data_batch -17.750715\n",
      "data_batch 6.4967403\n",
      "data_batch -1.6580781\n",
      "data_batch 11.522419\n",
      "data_batch -4.4986825\n",
      "data_batch -22.982676\n",
      "data_batch 15.394748\n",
      "data_batch -20.25215\n",
      "data_batch 7.494381\n",
      "data_batch 20.352703\n",
      "data_batch 2.4385304\n",
      "data_batch -12.499482\n",
      "data_batch -17.587654\n",
      "data_batch -0.76788634\n",
      "data_batch -0.120370865\n",
      "data_batch 29.029219\n",
      "data_batch 5.974866\n",
      "data_batch -12.254315\n",
      "data_batch 4.945433\n",
      "data_batch 1.5993121\n",
      "data_batch 11.465451\n",
      "data_batch 4.7220078\n",
      "data_batch 1.034271\n",
      "data_batch -3.539084\n",
      "data_batch 3.0163853\n",
      "data_batch 17.35527\n",
      "data_batch -5.2638364\n",
      "data_batch -12.104889\n",
      "data_batch 8.332419\n",
      "data_batch -0.18885241\n",
      "data_batch 0.32223043\n",
      "data_batch -1.5555216\n",
      "data_batch -2.9866967\n",
      "data_batch 10.977928\n",
      "data_batch 3.2986672\n",
      "data_batch 7.295881\n",
      "data_batch 17.855017\n",
      "data_batch -10.378533\n",
      "data_batch -17.418354\n",
      "data_batch 5.064064\n",
      "data_batch -2.8342793\n",
      "data_batch 0.6227175\n",
      "data_batch 0.93187463\n",
      "data_batch 2.800488\n",
      "data_batch 9.494835\n",
      "data_batch -1.5412045\n",
      "data_batch -6.1540327\n",
      "data_batch 2.6343727\n",
      "data_batch 0.19662072\n",
      "data_batch 16.52466\n",
      "data_batch -14.325371\n",
      "data_batch 1.1100736\n",
      "data_batch 16.159422\n",
      "data_batch 0.17701808\n",
      "data_batch -9.524035\n",
      "data_batch -7.551843\n",
      "data_batch -1.8266068\n",
      "data_batch -30.859838\n",
      "data_batch -10.112659\n",
      "data_batch 8.68127\n",
      "data_batch -3.8013756\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "NUM_THREADS = 4\n",
    "# Generating some simple data\n",
    "# todo create 1000 random samples, each is a 1D array from the normal distribution (10, 1)\n",
    "train = 10 * np.random.randn(N_SAMPLES, 4) + 1\n",
    "# todo create 1000 random labels of 0 and 1\n",
    "labels = np.random.randint(1, 2, size=N_SAMPLES)\n",
    "# todo create FIFOQueue\n",
    "queue = tf.FIFOQueue(capacity=50, dtypes=[tf.float32, tf.int32], shapes=[[4], []])\n",
    "\n",
    "enqueue_op = queue.enqueue_many([train, labels])\n",
    "data_sample, label_sample = queue.dequeue()\n",
    "\n",
    "# create ops that do something with data_sample and label_sample\n",
    "\n",
    "# todo create NUM_THREADS to do enqueue\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * NUM_THREADS)\n",
    "tf.train.add_queue_runner(qr)\n",
    "with tf.Session() as sess:\n",
    "    # create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "#     enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    for step in range(100):  # do to 100 iterations\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        data_batch, label_batch = sess.run([data_sample, label_sample])\n",
    "        print('data_batch', len(data_batch))\n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
